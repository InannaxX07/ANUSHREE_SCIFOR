{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0csoEPCFMxsLHhSUBUlqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InannaxX07/ANUSHREE_SCIFOR/blob/main/NLP_sentiment_analysis_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic sentiment analysis and text processing using the Natural Language Toolkit (NLTK) This code demonstrates basic sentiment analysis using VADER (Valence Aware Dictionary and sEntiment Reasoner) and text processing including tokenization and stopword removal."
      ],
      "metadata": {
        "id": "rZvcoHyaIaeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrvb6MFrG6Rr",
        "outputId": "0fddfcfa-7b64-41b3-9264-f7663e5bfd5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: {'neg': 0.0, 'neu': 0.287, 'pos': 0.713, 'compound': 0.9245}\n",
            "Processed text: ['love', 'product', 'amazing', 'works', 'great']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    return sid.polarity_scores(text)\n",
        "\n",
        "def process_text(text):\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "\n",
        "# Example usage\n",
        "text = \"I love this product! It's amazing and works great.\"\n",
        "sentiment = analyze_sentiment(text)\n",
        "processed_text = process_text(text)\n",
        "\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Processed text: {processed_text}\")"
      ]
    }
  ]
}